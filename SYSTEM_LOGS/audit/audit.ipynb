{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141ccecf",
   "metadata": {},
   "source": [
    "# audit.log íŒŒì¼ ì •ì œ \n",
    "- 2025ë…„ 9ì›” 23ì¼(í™”) - teams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas ì¶œë ¥ ì˜µì…˜ ì„¤ì • - 60ì¤„ê¹Œì§€ í‘œì‹œ\n",
    "pd.set_option('display.max_rows', 60)\n",
    "print(\"pandas ì¶œë ¥ ì˜µì…˜ì´ 60ì¤„ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf68232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¡œê·¸ í˜•ì‹ë³„ ì¹´ìš´íŠ¸\n",
      "JSON í˜•ì‹ (AUDIT_PAYLOAD): 4 ê±´ * ê° 200ê±´ = 800 ê±´\n",
      "Key=Value í˜•ì‹ (timestamp=...): 11200 ê±´\n",
      "ê·¸ ì™¸ ê¸°íƒ€ í˜•ì‹: 4382 ê±´\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# ë¡œê·¸ íŒŒì¼ ê²½ë¡œ\n",
    "log_file = \"/home/kongju/DATA/DREAM/teams/0923_audit.log\"\n",
    "\n",
    "# ì¹´ìš´íŠ¸ ë³€ìˆ˜\n",
    "json_count = 0\n",
    "keyval_count = 0\n",
    "other_count = 0\n",
    "\n",
    "# ì •ê·œì‹ íŒ¨í„´ ì •ì˜\n",
    "json_pattern = re.compile(r\"AUDIT_PAYLOAD\\s*{\")   # JSON í˜•ì‹ ë¡œê·¸\n",
    "keyval_pattern = re.compile(r\"timestamp=\\d{4}-\\d{2}-\\d{2}\")  # Key=Value ë¡œê·¸\n",
    "\n",
    "# íŒŒì¼ ì½ê¸°\n",
    "with open(log_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if json_pattern.search(line):\n",
    "            json_count += 1\n",
    "        elif keyval_pattern.search(line):\n",
    "            keyval_count += 1\n",
    "        else:\n",
    "            other_count += 1\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ë¡œê·¸ í˜•ì‹ë³„ ì¹´ìš´íŠ¸\")\n",
    "print(f\"JSON í˜•ì‹ (AUDIT_PAYLOAD): {json_count} ê±´ * ê° 200ê±´ = {json_count * 200} ê±´\")\n",
    "print(f\"Key=Value í˜•ì‹ (timestamp=...): {keyval_count} ê±´\")\n",
    "print(f\"ê·¸ ì™¸ ê¸°íƒ€ í˜•ì‹: {other_count} ê±´\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1550833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë¸”ë¡ 1] rows ì¼€ì´ìŠ¤ ê°œìˆ˜: 200 ê±´\n",
      "[ë¸”ë¡ 2] rows ì¼€ì´ìŠ¤ ê°œìˆ˜: 200 ê±´\n",
      "[ë¸”ë¡ 3] rows ì¼€ì´ìŠ¤ ê°œìˆ˜: 200 ê±´\n",
      "[ë¸”ë¡ 4] rows ì¼€ì´ìŠ¤ ê°œìˆ˜: 200 ê±´\n"
     ]
    }
   ],
   "source": [
    "# AUDIT_PAYLOAD ì¶”ì¶œìš© ì •ê·œì‹ (ì¤‘ê´„í˜¸ { } ê¹Œì§€ í¬í•¨)\n",
    "audit_pattern = re.compile(r\"AUDIT_PAYLOAD\\s+(\\{.*\\})\")\n",
    "\n",
    "# íŒŒì¼ ì½ê¸°\n",
    "with open(log_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "block_idx = 0\n",
    "for line in lines:\n",
    "    match = audit_pattern.search(line)\n",
    "    if match:\n",
    "        block_idx += 1\n",
    "        json_str = match.group(1)\n",
    "\n",
    "        try:\n",
    "            data = json.loads(json_str)   # JSON íŒŒì‹±\n",
    "            rows = data.get(\"rows\", [])\n",
    "            print(f\"[ë¸”ë¡ {block_idx}] rows ì¼€ì´ìŠ¤ ê°œìˆ˜: {len(rows)} ê±´\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"[ë¸”ë¡ {block_idx}] JSON íŒŒì‹± ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34393c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, csv, html\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "log_path = Path(log_file)  # Path ê°ì²´ë¡œ ë³€í™˜\n",
    "out_path = Path(\"/home/kongju/DREAM/SYSTEM_LOGS/audit/output/0923_audit.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39c38a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ëœ ì¸ì½”ë”©: utf-8\n",
      "ì²˜ë¦¬ ì¤‘... 1000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 923ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 2000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 1047ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 3000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 1172ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 4000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 1295ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 7000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 2136ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 8000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 3082ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 9000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 4019ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 10000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 4972ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 11000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 5922ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 12000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 6878ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 13000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 7854ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 14000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 8844ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 15000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 9834ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 16000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 10824ê°œ\n",
      "ì²˜ë¦¬ ì¤‘... 17000ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: 11814ê°œ\n",
      "âœ… ìœ íš¨í•œ ì¼€ì´ìŠ¤ 12000ê±´ì„ CSVë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤ â†’ /home/kongju/DREAM/audit/output/0923_audit.csv\n",
      "âš ï¸ ë¬´ì‹œëœ ë¶ˆì™„ì „í•œ ì¼€ì´ìŠ¤: 0ê±´\n",
      "ğŸ“Š ì „ì²´ ì²˜ë¦¬ í†µê³„:\n",
      "   - JSON ì¼€ì´ìŠ¤: 0ê±´\n",
      "   - í•œì¤„ key=value ì¼€ì´ìŠ¤: 0ê±´\n",
      "   - ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤: ë‚˜ë¨¸ì§€\n",
      "\n",
      "ğŸ” ì²˜ìŒ 5ê°œ ì¼€ì´ìŠ¤ ìƒ˜í”Œ:\n",
      "  1. timestamp: '2025-09-23  14:41:48', caseData: 'TEST_IDP, ì‹œë™ ì‹œ í…ŒìŠ¤íŠ¸...', caseUser: 'TEST_IDP'\n",
      "  2. timestamp: '2025-09-23  14:41:48', caseData: 'TEST_IDP, ì‹œë™ ì‹œ í…ŒìŠ¤íŠ¸...', caseUser: 'TEST_IDP'\n",
      "  3. timestamp: '2025-09-23  14:41:48', caseData: 'TEST_IDP, ì‹œë™ ì‹œ í…ŒìŠ¤íŠ¸...', caseUser: 'TEST_IDP'\n",
      "  4. timestamp: '2025-09-23  14:41:47', caseData: 'Key Encrypt Key íŒŒê¸°, 0 ìœ¼ë¡œ ë®ì–´ì“°ê¸°...', caseUser: 'TEST_IDP'\n",
      "  5. timestamp: '2025-09-23  14:41:47', caseData: 'Key Encrypt Key, SEED/CBC...', caseUser: 'TEST_IDP'\n"
     ]
    }
   ],
   "source": [
    "# ì›í•˜ëŠ” ì»¬ëŸ¼ ìˆœì„œ (no ì»¬ëŸ¼ì„ ë§¨ ì•ì— ì¶”ê°€)\n",
    "column_order = ['no', 'timestamp', 'caseData', 'index', 'caseResult', 'caseUser', 'caseType']\n",
    "\n",
    "rows_out = []\n",
    "\n",
    "# í•œê¸€ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„\n",
    "def detect_encoding(file_path):\n",
    "    encodings = ['cp949', 'euc-kr', 'utf-8', 'utf-8-sig']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with file_path.open(\"r\", encoding=encoding, errors=\"strict\") as f:\n",
    "                # ì²« 1000ì¤„ í…ŒìŠ¤íŠ¸í•´ì„œ í•œê¸€ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "                for i, line in enumerate(f):\n",
    "                    if i > 1000:\n",
    "                        break\n",
    "                # ì„±ê³µí•˜ë©´ ì¸ì½”ë”© ì´ë¦„ë§Œ ë°˜í™˜\n",
    "                return encoding\n",
    "        except:\n",
    "            continue\n",
    "    # ëª¨ë“  ì¸ì½”ë”©ì´ ì‹¤íŒ¨í•˜ë©´ utf-8 ë°˜í™˜\n",
    "    return \"utf-8\"\n",
    "\n",
    "def process_multiline_case(lines_buffer, debug=False):\n",
    "    \"\"\"ì—¬ëŸ¬ ì¤„ì— ê±¸ì¹œ key=value ì¼€ì´ìŠ¤ë¥¼ ì²˜ë¦¬\"\"\"\n",
    "    if not lines_buffer:\n",
    "        return None\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"=== ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤ ì²˜ë¦¬ ===\")\n",
    "        for i, line in enumerate(lines_buffer):\n",
    "            print(f\"  {i}: '{line.strip()}'\")\n",
    "    \n",
    "    kv_dict = {}\n",
    "    for line in lines_buffer:\n",
    "        line = line.strip()\n",
    "        if \"=\" in line:\n",
    "            k, v = line.split(\"=\", 1)\n",
    "            k = k.strip()\n",
    "            v = v.strip()\n",
    "            kv_dict[k] = v\n",
    "            if debug:\n",
    "                print(f\"    íŒŒì‹±: {k} = '{v}'\")\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"  ìµœì¢… ë”•ì…”ë„ˆë¦¬: {kv_dict}\")\n",
    "    \n",
    "    # ìµœì†Œí•œ timestampê°€ ìˆì–´ì•¼ ìœ íš¨í•œ ì¼€ì´ìŠ¤\n",
    "    if 'timestamp' not in kv_dict or not kv_dict['timestamp']:\n",
    "        if debug:\n",
    "            print(\"  --> timestamp ì—†ìŒ, ë¬´ì‹œ\")\n",
    "        return None\n",
    "    \n",
    "    # ìµœì†Œí•œ 2ê°œ ì´ìƒì˜ í•„ë“œê°€ ìˆì–´ì•¼ ìœ íš¨í•œ ì¼€ì´ìŠ¤ë¡œ ê°„ì£¼\n",
    "    valid_fields = sum(1 for v in kv_dict.values() if v and v.strip())\n",
    "    if valid_fields < 2:\n",
    "        if debug:\n",
    "            print(f\"  --> ìœ íš¨ í•„ë“œ {valid_fields}ê°œ, ë¬´ì‹œ\")\n",
    "        return None\n",
    "    \n",
    "    result = {\n",
    "        \"no\": len(rows_out) + 1,\n",
    "        \"timestamp\": kv_dict.get(\"timestamp\", \"\"),\n",
    "        \"caseData\": kv_dict.get(\"caseData\", \"\"),\n",
    "        \"index\": kv_dict.get(\"index\", \"\"),\n",
    "        \"caseResult\": kv_dict.get(\"caseResult\", \"\"),\n",
    "        \"caseUser\": kv_dict.get(\"caseUser\", \"\"),\n",
    "        \"caseType\": kv_dict.get(\"caseType\", \"\"),\n",
    "    }\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"  --> ìœ íš¨í•œ ì¼€ì´ìŠ¤: {result}\")\n",
    "        print(\"=\" * 40)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def is_indented_line(line):\n",
    "    \"\"\"ë“¤ì—¬ì“°ê¸°ëœ ë¼ì¸ì¸ì§€ í™•ì¸ (ê³µë°±ì´ë‚˜ íƒ­ìœ¼ë¡œ ì‹œì‘)\"\"\"\n",
    "    return line.startswith('  ') or line.startswith('\\t')\n",
    "\n",
    "def is_key_value_line(line):\n",
    "    \"\"\"key=value í˜•íƒœì˜ ë¼ì¸ì¸ì§€ í™•ì¸\"\"\"\n",
    "    stripped = line.strip()\n",
    "    return '=' in stripped and not stripped.startswith('=')\n",
    "\n",
    "# ì ì ˆí•œ ì¸ì½”ë”© ê°ì§€\n",
    "detected_encoding = detect_encoding(log_path)\n",
    "print(f\"ì‚¬ìš©ëœ ì¸ì½”ë”©: {detected_encoding}\")\n",
    "\n",
    "# ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë²„í¼\n",
    "multiline_buffer = []\n",
    "processed_count = 0\n",
    "skipped_incomplete = 0\n",
    "debug_mode = True  # ì²˜ìŒ ëª‡ ê°œ ì¼€ì´ìŠ¤ë§Œ ë””ë²„ê·¸ ì¶œë ¥\n",
    "\n",
    "# ê°ì§€ëœ ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì—´ê¸°\n",
    "with log_path.open(\"r\", encoding=detected_encoding, errors=\"replace\") as f:\n",
    "    for line_num, line in enumerate(f, 1):\n",
    "        original_line = line\n",
    "        line = line.rstrip('\\n\\r')  # ê°œí–‰ë¬¸ìë§Œ ì œê±°, ê³µë°±ì€ ìœ ì§€\n",
    "        \n",
    "        # ë¹ˆ ì¤„ ì²˜ë¦¬\n",
    "        if not line.strip():\n",
    "            # ë¹ˆ ì¤„ì´ ë‚˜ì˜¤ë©´ í˜„ì¬ ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤ ì™„ë£Œ\n",
    "            if multiline_buffer:\n",
    "                case = process_multiline_case(multiline_buffer, debug_mode and processed_count < 5)\n",
    "                if case:\n",
    "                    rows_out.append(case)\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    skipped_incomplete += 1\n",
    "                multiline_buffer = []\n",
    "            continue\n",
    "\n",
    "        # --- 1. JSON í˜•ì‹ (AUDIT_PAYLOAD) ì²˜ë¦¬ ---\n",
    "        if \"AUDIT_PAYLOAD\" in line:\n",
    "            # ì´ì „ì— ìŒ“ì¸ ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤ê°€ ìˆë‹¤ë©´ ì²˜ë¦¬\n",
    "            if multiline_buffer:\n",
    "                case = process_multiline_case(multiline_buffer, debug_mode and processed_count < 5)\n",
    "                if case:\n",
    "                    rows_out.append(case)\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    skipped_incomplete += 1\n",
    "                multiline_buffer = []\n",
    "            \n",
    "            try:\n",
    "                json_start = line.index(\"AUDIT_PAYLOAD\") + len(\"AUDIT_PAYLOAD\")\n",
    "                json_str = line[json_start:].strip()\n",
    "                first_brace = json_str.find(\"{\")\n",
    "                if first_brace == -1:\n",
    "                    continue\n",
    "                s = json_str[first_brace:]\n",
    "                depth, end_idx = 0, None\n",
    "                for i, ch in enumerate(s):\n",
    "                    if ch == \"{\":\n",
    "                        depth += 1\n",
    "                    elif ch == \"}\":\n",
    "                        depth -= 1\n",
    "                        if depth == 0:\n",
    "                            end_idx = i\n",
    "                            break\n",
    "                if end_idx is None:\n",
    "                    continue\n",
    "                payload = json.loads(s[: end_idx + 1])\n",
    "            except Exception as e:\n",
    "                if debug_mode:\n",
    "                    print(f\"JSON íŒŒì‹± ì˜¤ë¥˜ (ë¼ì¸ {line_num}): {e}\")\n",
    "                continue\n",
    "\n",
    "            for r in payload.get(\"rows\", []):\n",
    "                row = {\n",
    "                    \"no\": len(rows_out) + 1,\n",
    "                    \"timestamp\": html.unescape(r.get(\"logDatetime\", \"\")).replace(\"\\xa0\", \" \").strip(),\n",
    "                    \"caseData\": r.get(\"caseData\", \"\"),\n",
    "                    \"index\": r.get(\"index\", \"\"),\n",
    "                    \"caseResult\": r.get(\"caseResult\", \"\"),\n",
    "                    \"caseUser\": r.get(\"caseUser\", \"\"),\n",
    "                    \"caseType\": r.get(\"caseType\", \"\"),\n",
    "                }\n",
    "                rows_out.append(row)\n",
    "                processed_count += 1\n",
    "\n",
    "        # --- 2. í•œ ì¤„ Key=Value í˜•ì‹ ì²˜ë¦¬ ---\n",
    "        elif line.strip().startswith(\"timestamp=\") and \" caseData=\" in line:\n",
    "            # ì´ì „ì— ìŒ“ì¸ ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤ê°€ ìˆë‹¤ë©´ ì²˜ë¦¬\n",
    "            if multiline_buffer:\n",
    "                case = process_multiline_case(multiline_buffer, debug_mode and processed_count < 5)\n",
    "                if case:\n",
    "                    rows_out.append(case)\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    skipped_incomplete += 1\n",
    "                multiline_buffer = []\n",
    "            \n",
    "            # í•œ ì¤„ì— ëª¨ë“  key=valueê°€ ìˆëŠ” ê²½ìš°\n",
    "            parts = line.split()\n",
    "            kv_dict = {}\n",
    "            \n",
    "            # ë” ì •í™•í•œ íŒŒì‹±ì„ ìœ„í•´ ì •ê·œì‹ ì‚¬ìš©\n",
    "            import re\n",
    "            # key=value íŒ¨í„´ì„ ì°¾ë˜, valueì— ê³µë°±ì´ í¬í•¨ë  ìˆ˜ ìˆìŒì„ ê³ ë ¤\n",
    "            pattern = r'(\\w+)=([^=]*?)(?=\\s+\\w+=|$)'\n",
    "            matches = re.findall(pattern, line)\n",
    "            \n",
    "            for key, value in matches:\n",
    "                kv_dict[key.strip()] = value.strip()\n",
    "            \n",
    "            if debug_mode and processed_count < 5:\n",
    "                print(f\"=== í•œì¤„ ì¼€ì´ìŠ¤ (ë¼ì¸ {line_num}) ===\")\n",
    "                print(f\"  ì›ë³¸: '{line.strip()}'\")\n",
    "                print(f\"  íŒŒì‹± ê²°ê³¼: {kv_dict}\")\n",
    "            \n",
    "            if 'timestamp' in kv_dict:\n",
    "                row = {\n",
    "                    \"no\": len(rows_out) + 1,\n",
    "                    \"timestamp\": kv_dict.get(\"timestamp\", \"\"),\n",
    "                    \"caseData\": kv_dict.get(\"caseData\", \"\"),\n",
    "                    \"index\": kv_dict.get(\"index\", \"\"),\n",
    "                    \"caseResult\": kv_dict.get(\"caseResult\", \"\"),\n",
    "                    \"caseUser\": kv_dict.get(\"caseUser\", \"\"),\n",
    "                    \"caseType\": kv_dict.get(\"caseType\", \"\"),\n",
    "                }\n",
    "                rows_out.append(row)\n",
    "                processed_count += 1\n",
    "                \n",
    "                if debug_mode and processed_count <= 5:\n",
    "                    print(f\"  --> ì €ì¥ë¨: {row}\")\n",
    "                    print(\"=\" * 40)\n",
    "            else:\n",
    "                skipped_incomplete += 1\n",
    "\n",
    "        # --- 3. ë©€í‹°ë¼ì¸ Key=Value í˜•ì‹ ì²˜ë¦¬ ---\n",
    "        elif line.strip().startswith(\"timestamp=\"):\n",
    "            # ì´ì „ì— ìŒ“ì¸ ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤ê°€ ìˆë‹¤ë©´ ì²˜ë¦¬\n",
    "            if multiline_buffer:\n",
    "                case = process_multiline_case(multiline_buffer, debug_mode and processed_count < 5)\n",
    "                if case:\n",
    "                    rows_out.append(case)\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    skipped_incomplete += 1\n",
    "                multiline_buffer = []\n",
    "            \n",
    "            # ìƒˆë¡œìš´ ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤ ì‹œì‘\n",
    "            multiline_buffer = [line]\n",
    "            \n",
    "        elif multiline_buffer and (is_indented_line(line) or is_key_value_line(line)):\n",
    "            # í˜„ì¬ ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤ì— ì¶”ê°€\n",
    "            if debug_mode and processed_count < 5:\n",
    "                print(f\"ë©€í‹°ë¼ì¸ ì¶”ê°€ (ë¼ì¸ {line_num}): '{line.strip()}'\")\n",
    "            multiline_buffer.append(line)\n",
    "        \n",
    "        elif multiline_buffer:\n",
    "            # ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤ê°€ ì§„í–‰ ì¤‘ì¸ë° ê´€ë ¨ ì—†ëŠ” ì¤„ì„ ë§Œë‚œ ê²½ìš°\n",
    "            # í˜„ì¬ ì¼€ì´ìŠ¤ë¥¼ ì™„ë£Œí•˜ê³  ìƒˆë¡œìš´ ì¤„ ì²˜ë¦¬\n",
    "            case = process_multiline_case(multiline_buffer, debug_mode and processed_count < 5)\n",
    "            if case:\n",
    "                rows_out.append(case)\n",
    "                processed_count += 1\n",
    "            else:\n",
    "                skipped_incomplete += 1\n",
    "            multiline_buffer = []\n",
    "        \n",
    "        # ì§„í–‰ìƒí™© ì¶œë ¥\n",
    "        if line_num % 1000 == 0:\n",
    "            print(f\"ì²˜ë¦¬ ì¤‘... {line_num}ë²ˆì§¸ ë¼ì¸, ìœ íš¨í•œ ì¼€ì´ìŠ¤: {len(rows_out)}ê°œ\")\n",
    "\n",
    "# íŒŒì¼ ëì—ì„œ ë‚¨ì€ ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤ ì²˜ë¦¬\n",
    "if multiline_buffer:\n",
    "    case = process_multiline_case(multiline_buffer, debug_mode)\n",
    "    if case:\n",
    "        rows_out.append(case)\n",
    "        processed_count += 1\n",
    "    else:\n",
    "        skipped_incomplete += 1\n",
    "\n",
    "# CSV ì €ì¥ (ì§€ì •í•œ column_order ì ìš©)\n",
    "with out_path.open(\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=column_order)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows_out)\n",
    "\n",
    "print(f\"âœ… ìœ íš¨í•œ ì¼€ì´ìŠ¤ {len(rows_out)}ê±´ì„ CSVë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤ â†’ {out_path}\")\n",
    "print(f\"âš ï¸ ë¬´ì‹œëœ ë¶ˆì™„ì „í•œ ì¼€ì´ìŠ¤: {skipped_incomplete}ê±´\")\n",
    "print(f\"ğŸ“Š ì „ì²´ ì²˜ë¦¬ í†µê³„:\")\n",
    "print(f\"   - JSON ì¼€ì´ìŠ¤: {sum(1 for row in rows_out if 'AUDIT_PAYLOAD' in str(row))}ê±´\")\n",
    "print(f\"   - í•œì¤„ key=value ì¼€ì´ìŠ¤: {processed_count - skipped_incomplete - len(rows_out)}ê±´\")\n",
    "print(f\"   - ë©€í‹°ë¼ì¸ ì¼€ì´ìŠ¤: ë‚˜ë¨¸ì§€\")\n",
    "\n",
    "# ì²˜ìŒ 5ê°œ ê²°ê³¼ ìƒ˜í”Œ ì¶œë ¥\n",
    "print(f\"\\nğŸ” ì²˜ìŒ 5ê°œ ì¼€ì´ìŠ¤ ìƒ˜í”Œ:\")\n",
    "for i, row in enumerate(rows_out[:5]):\n",
    "    print(f\"  {i+1}. timestamp: '{row['timestamp']}', caseData: '{row['caseData'][:30]}...', caseUser: '{row['caseUser']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af95e25c",
   "metadata": {},
   "source": [
    "- ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37320a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 12000 case rows to: /home/kongju/DREAM/audit/output/0923_audit.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Excel íŒŒì¼ë¡œ ì €ì¥\n",
    "excel_path = out_path.with_suffix('.xlsx')\n",
    "df = pd.DataFrame(rows_out)\n",
    "df.to_excel(excel_path, index=False)\n",
    "print(f\"Saved {len(rows_out)} case rows to: {excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a80f15bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['no', 'timestamp', 'caseData', 'index', 'caseResult', 'caseUser', 'caseType'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "671c8227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caseUser ê³ ìœ  ê°’ ê°œìˆ˜: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "caseUser\n",
       "TEST_IDP    11542\n",
       "ssoadmin      274\n",
       "ssouser       124\n",
       "usertest       52\n",
       "ssodream        8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"caseUser ê³ ìœ  ê°’ ê°œìˆ˜: {df['caseUser'].nunique()}\")\n",
    "df['caseUser'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb7e42ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TEST_IDP', 'ssoadmin', 'usertest', 'ssouser', 'ssodream'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['caseUser'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "098aa05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caseType ê³ ìœ  ê°’ ê°œìˆ˜: 35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "caseType\n",
       "ì•”í˜¸í‚¤ íŒŒê¸°             2318\n",
       "ê°ì‚¬ ê¸°ëŠ¥ ì‹œì‘/ì¢…ë£Œ     2077\n",
       "ì•”í˜¸ëª¨ë“ˆ ìê°€ì‹œí—˜       2057\n",
       "ì•”í˜¸í‚¤ ìƒì„±             1137\n",
       "SSOí”„ë¡œì„¸ìŠ¤ í™•ì¸        1054\n",
       "SSOëª¨ë“ˆ ë¬´ê²°ì„± ê²€ì¦     1051\n",
       "??? ??                   607\n",
       "???? ????                331\n",
       "?? ?? ??/??              321\n",
       "SSO???? ??               173\n",
       "SSO?? ??? ??             172\n",
       "ê´€ë¦¬ì ë¡œê·¸ì¸ ìš”ì²­       138\n",
       "ì•”í˜¸ ì—°ì‚°                 66\n",
       "ì‚¬ìš©ì ë¡œê·¸ì¸ ìš”ì²­        63\n",
       "ì¸ì¦í† í° ìƒì„±             58\n",
       "?? ??                     50\n",
       "ì‚¬ìš©ì ì—°ê³„ ìš”ì²­          50\n",
       "??? ??? ??                40\n",
       "ê´€ë¦¬ì ë¡œê·¸ì•„ì›ƒ           34\n",
       "ë¹„ë°€ì •ë³´ íŒŒê¸°             34\n",
       "??? ?? ??                 32\n",
       "???? ??                   31\n",
       "??? ????                  24\n",
       "ê°ì‚¬ì •ë³´ ì„¤ì • ë³€ê²½        14\n",
       "ì‚¬ìš©ì ë¡œê·¸ì•„ì›ƒ           13\n",
       "???? ?? ??                10\n",
       "ì‚¬ìš©ì ì •ì±… ë³€ê²½           8\n",
       "ê´€ë¦¬ì ì •ë³´ ë³€ê²½           8\n",
       "??? ?? IP ??               5\n",
       "í´ë¼ì´ì–¸íŠ¸ ì •ë³´ ë³€ê²½       4\n",
       "ì‚¬ìš©ì ì •ë³´ ë³€ê²½           4\n",
       "ê´€ë¦¬ì ì ‘ì† IP ë³€ê²½        4\n",
       "ê´€ë¦¬ì ì •ì±… ë³€ê²½           4\n",
       "????? ?? ??                4\n",
       "ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ ë³€ê²½       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"caseType ê³ ìœ  ê°’ ê°œìˆ˜: {df['caseType'].nunique()}\")\n",
    "df['caseType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1f50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecca087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4dcc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4649e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
