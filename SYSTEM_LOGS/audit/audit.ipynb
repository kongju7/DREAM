{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141ccecf",
   "metadata": {},
   "source": [
    "# audit.log 파일 정제 \n",
    "- 2025년 9월 23일(화) - teams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas 출력 옵션 설정 - 60줄까지 표시\n",
    "pd.set_option('display.max_rows', 60)\n",
    "print(\"pandas 출력 옵션이 60줄로 설정되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf68232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로그 형식별 카운트\n",
      "JSON 형식 (AUDIT_PAYLOAD): 4 건 * 각 200건 = 800 건\n",
      "Key=Value 형식 (timestamp=...): 11200 건\n",
      "그 외 기타 형식: 4382 건\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# 로그 파일 경로\n",
    "log_file = \"/home/kongju/DATA/DREAM/teams/0923_audit.log\"\n",
    "\n",
    "# 카운트 변수\n",
    "json_count = 0\n",
    "keyval_count = 0\n",
    "other_count = 0\n",
    "\n",
    "# 정규식 패턴 정의\n",
    "json_pattern = re.compile(r\"AUDIT_PAYLOAD\\s*{\")   # JSON 형식 로그\n",
    "keyval_pattern = re.compile(r\"timestamp=\\d{4}-\\d{2}-\\d{2}\")  # Key=Value 로그\n",
    "\n",
    "# 파일 읽기\n",
    "with open(log_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if json_pattern.search(line):\n",
    "            json_count += 1\n",
    "        elif keyval_pattern.search(line):\n",
    "            keyval_count += 1\n",
    "        else:\n",
    "            other_count += 1\n",
    "\n",
    "# 결과 출력\n",
    "print(\"로그 형식별 카운트\")\n",
    "print(f\"JSON 형식 (AUDIT_PAYLOAD): {json_count} 건 * 각 200건 = {json_count * 200} 건\")\n",
    "print(f\"Key=Value 형식 (timestamp=...): {keyval_count} 건\")\n",
    "print(f\"그 외 기타 형식: {other_count} 건\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1550833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[블록 1] rows 케이스 개수: 200 건\n",
      "[블록 2] rows 케이스 개수: 200 건\n",
      "[블록 3] rows 케이스 개수: 200 건\n",
      "[블록 4] rows 케이스 개수: 200 건\n"
     ]
    }
   ],
   "source": [
    "# AUDIT_PAYLOAD 추출용 정규식 (중괄호 { } 까지 포함)\n",
    "audit_pattern = re.compile(r\"AUDIT_PAYLOAD\\s+(\\{.*\\})\")\n",
    "\n",
    "# 파일 읽기\n",
    "with open(log_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "block_idx = 0\n",
    "for line in lines:\n",
    "    match = audit_pattern.search(line)\n",
    "    if match:\n",
    "        block_idx += 1\n",
    "        json_str = match.group(1)\n",
    "\n",
    "        try:\n",
    "            data = json.loads(json_str)   # JSON 파싱\n",
    "            rows = data.get(\"rows\", [])\n",
    "            print(f\"[블록 {block_idx}] rows 케이스 개수: {len(rows)} 건\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"[블록 {block_idx}] JSON 파싱 오류: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34393c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, csv, html\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "log_path = Path(log_file)  # Path 객체로 변환\n",
    "out_path = Path(\"/home/kongju/DREAM/SYSTEM_LOGS/audit/output/0923_audit.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39c38a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용된 인코딩: utf-8\n",
      "처리 중... 1000번째 라인, 유효한 케이스: 923개\n",
      "처리 중... 2000번째 라인, 유효한 케이스: 1047개\n",
      "처리 중... 3000번째 라인, 유효한 케이스: 1172개\n",
      "처리 중... 4000번째 라인, 유효한 케이스: 1295개\n",
      "처리 중... 7000번째 라인, 유효한 케이스: 2136개\n",
      "처리 중... 8000번째 라인, 유효한 케이스: 3082개\n",
      "처리 중... 9000번째 라인, 유효한 케이스: 4019개\n",
      "처리 중... 10000번째 라인, 유효한 케이스: 4972개\n",
      "처리 중... 11000번째 라인, 유효한 케이스: 5922개\n",
      "처리 중... 12000번째 라인, 유효한 케이스: 6878개\n",
      "처리 중... 13000번째 라인, 유효한 케이스: 7854개\n",
      "처리 중... 14000번째 라인, 유효한 케이스: 8844개\n",
      "처리 중... 15000번째 라인, 유효한 케이스: 9834개\n",
      "처리 중... 16000번째 라인, 유효한 케이스: 10824개\n",
      "처리 중... 17000번째 라인, 유효한 케이스: 11814개\n",
      "✅ 유효한 케이스 12000건을 CSV로 저장했습니다 → /home/kongju/DREAM/audit/output/0923_audit.csv\n",
      "⚠️ 무시된 불완전한 케이스: 0건\n",
      "📊 전체 처리 통계:\n",
      "   - JSON 케이스: 0건\n",
      "   - 한줄 key=value 케이스: 0건\n",
      "   - 멀티라인 케이스: 나머지\n",
      "\n",
      "🔍 처음 5개 케이스 샘플:\n",
      "  1. timestamp: '2025-09-23  14:41:48', caseData: 'TEST_IDP, 시동 시 테스트...', caseUser: 'TEST_IDP'\n",
      "  2. timestamp: '2025-09-23  14:41:48', caseData: 'TEST_IDP, 시동 시 테스트...', caseUser: 'TEST_IDP'\n",
      "  3. timestamp: '2025-09-23  14:41:48', caseData: 'TEST_IDP, 시동 시 테스트...', caseUser: 'TEST_IDP'\n",
      "  4. timestamp: '2025-09-23  14:41:47', caseData: 'Key Encrypt Key 파기, 0 으로 덮어쓰기...', caseUser: 'TEST_IDP'\n",
      "  5. timestamp: '2025-09-23  14:41:47', caseData: 'Key Encrypt Key, SEED/CBC...', caseUser: 'TEST_IDP'\n"
     ]
    }
   ],
   "source": [
    "# 원하는 컬럼 순서 (no 컬럼을 맨 앞에 추가)\n",
    "column_order = ['no', 'timestamp', 'caseData', 'index', 'caseResult', 'caseUser', 'caseType']\n",
    "\n",
    "rows_out = []\n",
    "\n",
    "# 한글 처리를 위해 여러 인코딩 시도\n",
    "def detect_encoding(file_path):\n",
    "    encodings = ['cp949', 'euc-kr', 'utf-8', 'utf-8-sig']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with file_path.open(\"r\", encoding=encoding, errors=\"strict\") as f:\n",
    "                # 첫 1000줄 테스트해서 한글이 있는지 확인\n",
    "                for i, line in enumerate(f):\n",
    "                    if i > 1000:\n",
    "                        break\n",
    "                # 성공하면 인코딩 이름만 반환\n",
    "                return encoding\n",
    "        except:\n",
    "            continue\n",
    "    # 모든 인코딩이 실패하면 utf-8 반환\n",
    "    return \"utf-8\"\n",
    "\n",
    "def process_multiline_case(lines_buffer, debug=False):\n",
    "    \"\"\"여러 줄에 걸친 key=value 케이스를 처리\"\"\"\n",
    "    if not lines_buffer:\n",
    "        return None\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"=== 멀티라인 케이스 처리 ===\")\n",
    "        for i, line in enumerate(lines_buffer):\n",
    "            print(f\"  {i}: '{line.strip()}'\")\n",
    "    \n",
    "    kv_dict = {}\n",
    "    for line in lines_buffer:\n",
    "        line = line.strip()\n",
    "        if \"=\" in line:\n",
    "            k, v = line.split(\"=\", 1)\n",
    "            k = k.strip()\n",
    "            v = v.strip()\n",
    "            kv_dict[k] = v\n",
    "            if debug:\n",
    "                print(f\"    파싱: {k} = '{v}'\")\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"  최종 딕셔너리: {kv_dict}\")\n",
    "    \n",
    "    # 최소한 timestamp가 있어야 유효한 케이스\n",
    "    if 'timestamp' not in kv_dict or not kv_dict['timestamp']:\n",
    "        if debug:\n",
    "            print(\"  --> timestamp 없음, 무시\")\n",
    "        return None\n",
    "    \n",
    "    # 최소한 2개 이상의 필드가 있어야 유효한 케이스로 간주\n",
    "    valid_fields = sum(1 for v in kv_dict.values() if v and v.strip())\n",
    "    if valid_fields < 2:\n",
    "        if debug:\n",
    "            print(f\"  --> 유효 필드 {valid_fields}개, 무시\")\n",
    "        return None\n",
    "    \n",
    "    result = {\n",
    "        \"no\": len(rows_out) + 1,\n",
    "        \"timestamp\": kv_dict.get(\"timestamp\", \"\"),\n",
    "        \"caseData\": kv_dict.get(\"caseData\", \"\"),\n",
    "        \"index\": kv_dict.get(\"index\", \"\"),\n",
    "        \"caseResult\": kv_dict.get(\"caseResult\", \"\"),\n",
    "        \"caseUser\": kv_dict.get(\"caseUser\", \"\"),\n",
    "        \"caseType\": kv_dict.get(\"caseType\", \"\"),\n",
    "    }\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"  --> 유효한 케이스: {result}\")\n",
    "        print(\"=\" * 40)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def is_indented_line(line):\n",
    "    \"\"\"들여쓰기된 라인인지 확인 (공백이나 탭으로 시작)\"\"\"\n",
    "    return line.startswith('  ') or line.startswith('\\t')\n",
    "\n",
    "def is_key_value_line(line):\n",
    "    \"\"\"key=value 형태의 라인인지 확인\"\"\"\n",
    "    stripped = line.strip()\n",
    "    return '=' in stripped and not stripped.startswith('=')\n",
    "\n",
    "# 적절한 인코딩 감지\n",
    "detected_encoding = detect_encoding(log_path)\n",
    "print(f\"사용된 인코딩: {detected_encoding}\")\n",
    "\n",
    "# 멀티라인 케이스 처리를 위한 버퍼\n",
    "multiline_buffer = []\n",
    "processed_count = 0\n",
    "skipped_incomplete = 0\n",
    "debug_mode = True  # 처음 몇 개 케이스만 디버그 출력\n",
    "\n",
    "# 감지된 인코딩으로 파일 열기\n",
    "with log_path.open(\"r\", encoding=detected_encoding, errors=\"replace\") as f:\n",
    "    for line_num, line in enumerate(f, 1):\n",
    "        original_line = line\n",
    "        line = line.rstrip('\\n\\r')  # 개행문자만 제거, 공백은 유지\n",
    "        \n",
    "        # 빈 줄 처리\n",
    "        if not line.strip():\n",
    "            # 빈 줄이 나오면 현재 멀티라인 케이스 완료\n",
    "            if multiline_buffer:\n",
    "                case = process_multiline_case(multiline_buffer, debug_mode and processed_count < 5)\n",
    "                if case:\n",
    "                    rows_out.append(case)\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    skipped_incomplete += 1\n",
    "                multiline_buffer = []\n",
    "            continue\n",
    "\n",
    "        # --- 1. JSON 형식 (AUDIT_PAYLOAD) 처리 ---\n",
    "        if \"AUDIT_PAYLOAD\" in line:\n",
    "            # 이전에 쌓인 멀티라인 케이스가 있다면 처리\n",
    "            if multiline_buffer:\n",
    "                case = process_multiline_case(multiline_buffer, debug_mode and processed_count < 5)\n",
    "                if case:\n",
    "                    rows_out.append(case)\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    skipped_incomplete += 1\n",
    "                multiline_buffer = []\n",
    "            \n",
    "            try:\n",
    "                json_start = line.index(\"AUDIT_PAYLOAD\") + len(\"AUDIT_PAYLOAD\")\n",
    "                json_str = line[json_start:].strip()\n",
    "                first_brace = json_str.find(\"{\")\n",
    "                if first_brace == -1:\n",
    "                    continue\n",
    "                s = json_str[first_brace:]\n",
    "                depth, end_idx = 0, None\n",
    "                for i, ch in enumerate(s):\n",
    "                    if ch == \"{\":\n",
    "                        depth += 1\n",
    "                    elif ch == \"}\":\n",
    "                        depth -= 1\n",
    "                        if depth == 0:\n",
    "                            end_idx = i\n",
    "                            break\n",
    "                if end_idx is None:\n",
    "                    continue\n",
    "                payload = json.loads(s[: end_idx + 1])\n",
    "            except Exception as e:\n",
    "                if debug_mode:\n",
    "                    print(f\"JSON 파싱 오류 (라인 {line_num}): {e}\")\n",
    "                continue\n",
    "\n",
    "            for r in payload.get(\"rows\", []):\n",
    "                row = {\n",
    "                    \"no\": len(rows_out) + 1,\n",
    "                    \"timestamp\": html.unescape(r.get(\"logDatetime\", \"\")).replace(\"\\xa0\", \" \").strip(),\n",
    "                    \"caseData\": r.get(\"caseData\", \"\"),\n",
    "                    \"index\": r.get(\"index\", \"\"),\n",
    "                    \"caseResult\": r.get(\"caseResult\", \"\"),\n",
    "                    \"caseUser\": r.get(\"caseUser\", \"\"),\n",
    "                    \"caseType\": r.get(\"caseType\", \"\"),\n",
    "                }\n",
    "                rows_out.append(row)\n",
    "                processed_count += 1\n",
    "\n",
    "        # --- 2. 한 줄 Key=Value 형식 처리 ---\n",
    "        elif line.strip().startswith(\"timestamp=\") and \" caseData=\" in line:\n",
    "            # 이전에 쌓인 멀티라인 케이스가 있다면 처리\n",
    "            if multiline_buffer:\n",
    "                case = process_multiline_case(multiline_buffer, debug_mode and processed_count < 5)\n",
    "                if case:\n",
    "                    rows_out.append(case)\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    skipped_incomplete += 1\n",
    "                multiline_buffer = []\n",
    "            \n",
    "            # 한 줄에 모든 key=value가 있는 경우\n",
    "            parts = line.split()\n",
    "            kv_dict = {}\n",
    "            \n",
    "            # 더 정확한 파싱을 위해 정규식 사용\n",
    "            import re\n",
    "            # key=value 패턴을 찾되, value에 공백이 포함될 수 있음을 고려\n",
    "            pattern = r'(\\w+)=([^=]*?)(?=\\s+\\w+=|$)'\n",
    "            matches = re.findall(pattern, line)\n",
    "            \n",
    "            for key, value in matches:\n",
    "                kv_dict[key.strip()] = value.strip()\n",
    "            \n",
    "            if debug_mode and processed_count < 5:\n",
    "                print(f\"=== 한줄 케이스 (라인 {line_num}) ===\")\n",
    "                print(f\"  원본: '{line.strip()}'\")\n",
    "                print(f\"  파싱 결과: {kv_dict}\")\n",
    "            \n",
    "            if 'timestamp' in kv_dict:\n",
    "                row = {\n",
    "                    \"no\": len(rows_out) + 1,\n",
    "                    \"timestamp\": kv_dict.get(\"timestamp\", \"\"),\n",
    "                    \"caseData\": kv_dict.get(\"caseData\", \"\"),\n",
    "                    \"index\": kv_dict.get(\"index\", \"\"),\n",
    "                    \"caseResult\": kv_dict.get(\"caseResult\", \"\"),\n",
    "                    \"caseUser\": kv_dict.get(\"caseUser\", \"\"),\n",
    "                    \"caseType\": kv_dict.get(\"caseType\", \"\"),\n",
    "                }\n",
    "                rows_out.append(row)\n",
    "                processed_count += 1\n",
    "                \n",
    "                if debug_mode and processed_count <= 5:\n",
    "                    print(f\"  --> 저장됨: {row}\")\n",
    "                    print(\"=\" * 40)\n",
    "            else:\n",
    "                skipped_incomplete += 1\n",
    "\n",
    "        # --- 3. 멀티라인 Key=Value 형식 처리 ---\n",
    "        elif line.strip().startswith(\"timestamp=\"):\n",
    "            # 이전에 쌓인 멀티라인 케이스가 있다면 처리\n",
    "            if multiline_buffer:\n",
    "                case = process_multiline_case(multiline_buffer, debug_mode and processed_count < 5)\n",
    "                if case:\n",
    "                    rows_out.append(case)\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    skipped_incomplete += 1\n",
    "                multiline_buffer = []\n",
    "            \n",
    "            # 새로운 멀티라인 케이스 시작\n",
    "            multiline_buffer = [line]\n",
    "            \n",
    "        elif multiline_buffer and (is_indented_line(line) or is_key_value_line(line)):\n",
    "            # 현재 멀티라인 케이스에 추가\n",
    "            if debug_mode and processed_count < 5:\n",
    "                print(f\"멀티라인 추가 (라인 {line_num}): '{line.strip()}'\")\n",
    "            multiline_buffer.append(line)\n",
    "        \n",
    "        elif multiline_buffer:\n",
    "            # 멀티라인 케이스가 진행 중인데 관련 없는 줄을 만난 경우\n",
    "            # 현재 케이스를 완료하고 새로운 줄 처리\n",
    "            case = process_multiline_case(multiline_buffer, debug_mode and processed_count < 5)\n",
    "            if case:\n",
    "                rows_out.append(case)\n",
    "                processed_count += 1\n",
    "            else:\n",
    "                skipped_incomplete += 1\n",
    "            multiline_buffer = []\n",
    "        \n",
    "        # 진행상황 출력\n",
    "        if line_num % 1000 == 0:\n",
    "            print(f\"처리 중... {line_num}번째 라인, 유효한 케이스: {len(rows_out)}개\")\n",
    "\n",
    "# 파일 끝에서 남은 멀티라인 케이스 처리\n",
    "if multiline_buffer:\n",
    "    case = process_multiline_case(multiline_buffer, debug_mode)\n",
    "    if case:\n",
    "        rows_out.append(case)\n",
    "        processed_count += 1\n",
    "    else:\n",
    "        skipped_incomplete += 1\n",
    "\n",
    "# CSV 저장 (지정한 column_order 적용)\n",
    "with out_path.open(\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=column_order)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows_out)\n",
    "\n",
    "print(f\"✅ 유효한 케이스 {len(rows_out)}건을 CSV로 저장했습니다 → {out_path}\")\n",
    "print(f\"⚠️ 무시된 불완전한 케이스: {skipped_incomplete}건\")\n",
    "print(f\"📊 전체 처리 통계:\")\n",
    "print(f\"   - JSON 케이스: {sum(1 for row in rows_out if 'AUDIT_PAYLOAD' in str(row))}건\")\n",
    "print(f\"   - 한줄 key=value 케이스: {processed_count - skipped_incomplete - len(rows_out)}건\")\n",
    "print(f\"   - 멀티라인 케이스: 나머지\")\n",
    "\n",
    "# 처음 5개 결과 샘플 출력\n",
    "print(f\"\\n🔍 처음 5개 케이스 샘플:\")\n",
    "for i, row in enumerate(rows_out[:5]):\n",
    "    print(f\"  {i+1}. timestamp: '{row['timestamp']}', caseData: '{row['caseData'][:30]}...', caseUser: '{row['caseUser']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af95e25c",
   "metadata": {},
   "source": [
    "- 엑셀 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37320a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 12000 case rows to: /home/kongju/DREAM/audit/output/0923_audit.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Excel 파일로 저장\n",
    "excel_path = out_path.with_suffix('.xlsx')\n",
    "df = pd.DataFrame(rows_out)\n",
    "df.to_excel(excel_path, index=False)\n",
    "print(f\"Saved {len(rows_out)} case rows to: {excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a80f15bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['no', 'timestamp', 'caseData', 'index', 'caseResult', 'caseUser', 'caseType'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "671c8227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caseUser 고유 값 개수: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "caseUser\n",
       "TEST_IDP    11542\n",
       "ssoadmin      274\n",
       "ssouser       124\n",
       "usertest       52\n",
       "ssodream        8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"caseUser 고유 값 개수: {df['caseUser'].nunique()}\")\n",
    "df['caseUser'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb7e42ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TEST_IDP', 'ssoadmin', 'usertest', 'ssouser', 'ssodream'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['caseUser'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "098aa05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caseType 고유 값 개수: 35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "caseType\n",
       "암호키 파기             2318\n",
       "감사 기능 시작/종료     2077\n",
       "암호모듈 자가시험       2057\n",
       "암호키 생성             1137\n",
       "SSO프로세스 확인        1054\n",
       "SSO모듈 무결성 검증     1051\n",
       "??? ??                   607\n",
       "???? ????                331\n",
       "?? ?? ??/??              321\n",
       "SSO???? ??               173\n",
       "SSO?? ??? ??             172\n",
       "관리자 로그인 요청       138\n",
       "암호 연산                 66\n",
       "사용자 로그인 요청        63\n",
       "인증토큰 생성             58\n",
       "?? ??                     50\n",
       "사용자 연계 요청          50\n",
       "??? ??? ??                40\n",
       "관리자 로그아웃           34\n",
       "비밀정보 파기             34\n",
       "??? ?? ??                 32\n",
       "???? ??                   31\n",
       "??? ????                  24\n",
       "감사정보 설정 변경        14\n",
       "사용자 로그아웃           13\n",
       "???? ?? ??                10\n",
       "사용자 정책 변경           8\n",
       "관리자 정보 변경           8\n",
       "??? ?? IP ??               5\n",
       "클라이언트 정보 변경       4\n",
       "사용자 정보 변경           4\n",
       "관리자 접속 IP 변경        4\n",
       "관리자 정책 변경           4\n",
       "????? ?? ??                4\n",
       "관리자 비밀번호 변경       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"caseType 고유 값 개수: {df['caseType'].nunique()}\")\n",
    "df['caseType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1f50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecca087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4dcc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4649e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
